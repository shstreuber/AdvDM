{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shstreuber/AdvDM/blob/main/Module14_PythonCats_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Kh5bL3xTZe"
      },
      "source": [
        "# **Module 14: Analyzing Unstructured Data**\n",
        "\n",
        "So far we have been dealing with **structured data**. Structured data is ... well ... structured. This means that an instance of our data has nice attributes that can be represented in a DataFrame or a table. But the majority of data in the world is **unstructured**.\n",
        "\n",
        "In this module you will learn how to:\n",
        "* Analyze unstructured text\n",
        "* Clean text with nltk tools\n",
        "* Build a word cloud\n",
        "* Find a source to help you build a sentiment analysis\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2sjob0bdK_o"
      },
      "source": [
        "# **Analyzing Text**\n",
        "Suppose I have a corpus of twitter posts about cats and my goal is to match the query for \"Healthy cat food\" to the most appropriate tweet I have found.\n",
        "\n",
        "A common way to represent text is to treat the text as an unordered set of words, which is called the **bag of words** approach.\n",
        "\n",
        "## Bag of Words\n",
        "\n",
        "With the bag of words approach we count word occurrences and the features (what we might think of as columns) are the words. This 'bag of words' allows us to use any classification methods we may want to use later. But first, we need to cover some extensive preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atsHOLBx3_os"
      },
      "source": [
        "##**0. Our Data** ##\n",
        "Let's assume that we have downloaded a number of tweets from Twitter. Note that each tweet is treated as a string and is stored in a variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVbii_xW4FSb"
      },
      "source": [
        "doc1 = \"Stray cats are running all over the place. I see 10 a day!\"\n",
        "doc2 = \"Cats are killers. They kill billions of animals a year.\"\n",
        "doc3 = \"The best food in Columbus, OH is the North Market.\"\n",
        "doc4 = \"Brand A is the best tasting cat food around. Your cat will love it.\"\n",
        "doc5 = \"Buy Brand C cat food for your cat. Brand C makes healthy and happy cats.\"\n",
        "doc6 = \"The Arnold Classic came to town this weekend. It reminds us to be healthy.\"\n",
        "doc7 = \"I have nothing to say. In summary, I have told you nothing.\"\n",
        "doc8 = \"Healthy cat food.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0pYkjSazLv2"
      },
      "source": [
        "## **1. Transform our text into an Array of Text Vectors**\n",
        "Converting **unstructured** text to something **structured** is a multistep process. Let's learn the bits before putting it together. And we will start with the last step first-- creating the bag of words.\n",
        "\n",
        "A CountVectorizer converts a collection of text documents to a matrix of token counts. Follow the link below to see how the CountVectorizer contains methods that helps us preprocess our text:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qovV5Lv7xTZy"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDEmR3z6xTa_"
      },
      "source": [
        "Now we assemble our separate text vectors into an array (i.e. a corpus of text) and call it tinyCorpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUafeTzqxTbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6771f40f-5bbd-435d-d3eb-1c08c121b8b1"
      },
      "source": [
        "tinyCorpus = [doc1,doc2,doc3,doc4,doc5,doc6,doc7,doc8]\n",
        "tinyCorpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Stray cats are running all over the place. I see 10 a day!',\n",
              " 'Cats are killers. They kill billions of animals a year.',\n",
              " 'The best food in Columbus, OH is the North Market.',\n",
              " 'Brand A is the best tasting cat food around. Your cat will love it.',\n",
              " 'Buy Brand C cat food for your cat. Brand C makes healthy and happy cats.',\n",
              " 'The Arnold Classic came to town this weekend. It reminds us to be healthy.',\n",
              " 'I have nothing to say. In summary, I have told you nothing.',\n",
              " 'Healthy cat food.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf-OzjBJ4PBN"
      },
      "source": [
        "## **2. Clean and Transform Text**\n",
        "For much of this we use the Natural Language Toolkit (NLTK): The complete toolkit for all NLP techniques [is here](https://www.nltk.org/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKE8moawvI0s"
      },
      "source": [
        "###**2.1 Transform tinyCorpus to String to Clean and Transform the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjunBpsQvhA5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3bcc7799-cbe0-423b-88ae-6d0994b85023"
      },
      "source": [
        "tinyCorpusStr=str(tinyCorpus)\n",
        "tinyCorpusStr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"['Stray cats are running all over the place. I see 10 a day!', 'Cats are killers. They kill billions of animals a year.', 'The best food in Columbus, OH is the North Market.', 'Brand A is the best tasting cat food around. Your cat will love it.', 'Buy Brand C cat food for your cat. Brand C makes healthy and happy cats.', 'The Arnold Classic came to town this weekend. It reminds us to be healthy.', 'I have nothing to say. In summary, I have told you nothing.', 'Healthy cat food.']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TmybhABvkgV"
      },
      "source": [
        "### **2.2 Remove any HTML tags**\n",
        "This is useful for webscraped data. We don't have any HTML tags here, but the code is still important."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO4WpIlQxMws",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "74ac8488-0f1d-40c4-e8a6-b62f36c1835f"
      },
      "source": [
        "import re\n",
        "clean = re.compile('<.*?>')\n",
        "tinyCorpusStrHTML = re.sub(clean, '', tinyCorpusStr)\n",
        "tinyCorpusStrHTML"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"['Stray cats are running all over the place. I see 10 a day!', 'Cats are killers. They kill billions of animals a year.', 'The best food in Columbus, OH is the North Market.', 'Brand A is the best tasting cat food around. Your cat will love it.', 'Buy Brand C cat food for your cat. Brand C makes healthy and happy cats.', 'The Arnold Classic came to town this weekend. It reminds us to be healthy.', 'I have nothing to say. In summary, I have told you nothing.', 'Healthy cat food.']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU7M_s27xNuU"
      },
      "source": [
        "###**2.3 Make All Characters Lowercase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWWYb03Av3RM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "19370e1a-0159-47bf-d399-164bb69230a6"
      },
      "source": [
        "tinyCorpusStrLower=tinyCorpusStr.lower()\n",
        "tinyCorpusStrLower"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"['stray cats are running all over the place. i see 10 a day!', 'cats are killers. they kill billions of animals a year.', 'the best food in columbus, oh is the north market.', 'brand a is the best tasting cat food around. your cat will love it.', 'buy brand c cat food for your cat. brand c makes healthy and happy cats.', 'the arnold classic came to town this weekend. it reminds us to be healthy.', 'i have nothing to say. in summary, i have told you nothing.', 'healthy cat food.']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsEE3XI4yCUT"
      },
      "source": [
        "### **2.4 Remove any Punctuation**\n",
        "You can do this in different ways. One of the ways is to set up a punctuation variable and then eliminate the contents of this variable from the string. Another is to use regular expressions. We will use the second option because it is more effective. For that, we need the Regular Expression library called re at https://docs.python.org/3/library/re.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCRK6q1hyKyv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fff042b2-eda6-45b2-f108-88d55364b0fc"
      },
      "source": [
        "import re\n",
        "\n",
        "tinyCorpusStrLowerPunct = re.sub(r'[^\\w\\s]', '', tinyCorpusStrLower)\n",
        "tinyCorpusStrLowerPunct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stray cats are running all over the place i see 10 a day cats are killers they kill billions of animals a year the best food in columbus oh is the north market brand a is the best tasting cat food around your cat will love it buy brand c cat food for your cat brand c makes healthy and happy cats the arnold classic came to town this weekend it reminds us to be healthy i have nothing to say in summary i have told you nothing healthy cat food'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCqc-tPx_PPU"
      },
      "source": [
        "###**2.5 Remove any Numbers**\n",
        "You may or may not want to do this, depending on whether the numbers in your text are important.\n",
        "\n",
        "NOTE that the code below still needs to be fixed because it separates the words into individual letters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63limMIf_ZuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b93dcc-f487-4dee-cd8b-e9ac835688e4"
      },
      "source": [
        "from string import digits\n",
        "\n",
        "remove_digits = str.maketrans('', '', digits)\n",
        "\n",
        "tinyCorpusStrLowerPunctNum1 = [i.translate(remove_digits) for i in tinyCorpusStrLowerPunct]\n",
        "\n",
        "print(tinyCorpusStrLowerPunctNum1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['s', 't', 'r', 'a', 'y', ' ', 'c', 'a', 't', 's', ' ', 'a', 'r', 'e', ' ', 'r', 'u', 'n', 'n', 'i', 'n', 'g', ' ', 'a', 'l', 'l', ' ', 'o', 'v', 'e', 'r', ' ', 't', 'h', 'e', ' ', 'p', 'l', 'a', 'c', 'e', ' ', 'i', ' ', 's', 'e', 'e', ' ', '', '', ' ', 'a', ' ', 'd', 'a', 'y', ' ', 'c', 'a', 't', 's', ' ', 'a', 'r', 'e', ' ', 'k', 'i', 'l', 'l', 'e', 'r', 's', ' ', 't', 'h', 'e', 'y', ' ', 'k', 'i', 'l', 'l', ' ', 'b', 'i', 'l', 'l', 'i', 'o', 'n', 's', ' ', 'o', 'f', ' ', 'a', 'n', 'i', 'm', 'a', 'l', 's', ' ', 'a', ' ', 'y', 'e', 'a', 'r', ' ', 't', 'h', 'e', ' ', 'b', 'e', 's', 't', ' ', 'f', 'o', 'o', 'd', ' ', 'i', 'n', ' ', 'c', 'o', 'l', 'u', 'm', 'b', 'u', 's', ' ', 'o', 'h', ' ', 'i', 's', ' ', 't', 'h', 'e', ' ', 'n', 'o', 'r', 't', 'h', ' ', 'm', 'a', 'r', 'k', 'e', 't', ' ', 'b', 'r', 'a', 'n', 'd', ' ', 'a', ' ', 'i', 's', ' ', 't', 'h', 'e', ' ', 'b', 'e', 's', 't', ' ', 't', 'a', 's', 't', 'i', 'n', 'g', ' ', 'c', 'a', 't', ' ', 'f', 'o', 'o', 'd', ' ', 'a', 'r', 'o', 'u', 'n', 'd', ' ', 'y', 'o', 'u', 'r', ' ', 'c', 'a', 't', ' ', 'w', 'i', 'l', 'l', ' ', 'l', 'o', 'v', 'e', ' ', 'i', 't', ' ', 'b', 'u', 'y', ' ', 'b', 'r', 'a', 'n', 'd', ' ', 'c', ' ', 'c', 'a', 't', ' ', 'f', 'o', 'o', 'd', ' ', 'f', 'o', 'r', ' ', 'y', 'o', 'u', 'r', ' ', 'c', 'a', 't', ' ', 'b', 'r', 'a', 'n', 'd', ' ', 'c', ' ', 'm', 'a', 'k', 'e', 's', ' ', 'h', 'e', 'a', 'l', 't', 'h', 'y', ' ', 'a', 'n', 'd', ' ', 'h', 'a', 'p', 'p', 'y', ' ', 'c', 'a', 't', 's', ' ', 't', 'h', 'e', ' ', 'a', 'r', 'n', 'o', 'l', 'd', ' ', 'c', 'l', 'a', 's', 's', 'i', 'c', ' ', 'c', 'a', 'm', 'e', ' ', 't', 'o', ' ', 't', 'o', 'w', 'n', ' ', 't', 'h', 'i', 's', ' ', 'w', 'e', 'e', 'k', 'e', 'n', 'd', ' ', 'i', 't', ' ', 'r', 'e', 'm', 'i', 'n', 'd', 's', ' ', 'u', 's', ' ', 't', 'o', ' ', 'b', 'e', ' ', 'h', 'e', 'a', 'l', 't', 'h', 'y', ' ', 'i', ' ', 'h', 'a', 'v', 'e', ' ', 'n', 'o', 't', 'h', 'i', 'n', 'g', ' ', 't', 'o', ' ', 's', 'a', 'y', ' ', 'i', 'n', ' ', 's', 'u', 'm', 'm', 'a', 'r', 'y', ' ', 'i', ' ', 'h', 'a', 'v', 'e', ' ', 't', 'o', 'l', 'd', ' ', 'y', 'o', 'u', ' ', 'n', 'o', 't', 'h', 'i', 'n', 'g', ' ', 'h', 'e', 'a', 'l', 't', 'h', 'y', ' ', 'c', 'a', 't', ' ', 'f', 'o', 'o', 'd']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlMDlMSvxTdo"
      },
      "source": [
        "## **3. Eliminate Low-Information words**\n",
        "For some applications, some words provide less information than others. For example,  the word *this* may be informative for some tasks. But for other tasks like deciding if the text is about pianos or motorcycles the word is considered uninformative. Other examples  of low-information words might be *the, a, this, that, on, of,*\n",
        "\n",
        "Some data scientists believe that these low-information, high-frequency words constitute noise and they remove them in a pre-processing step. These words we are removing are called **stop words**\n",
        "\n",
        "For example, if the stop words are *a, and, be, the, will* and we have the sentence\n",
        "\n",
        "         be a kind and compassionate person\n",
        "         \n",
        "we will end up with\n",
        "\n",
        "              kind    compassionate  person"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxI3KqwL740j"
      },
      "source": [
        "###**3.0 Remove Noise**\n",
        "BEFORE we apply any canned stopword lists, we can also decide to make additional noise lists ourselves. For example, the letter \"c\", the letters \"us\", and the word \"oh\" show up in our text. We will remove them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAxPy8gWE8xX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "52996482-404f-4327-b55c-02aa1eb718c1"
      },
      "source": [
        "noise_list = [\"oh\", \"c\", \"us\"]\n",
        "def _remove_noise(input_text):\n",
        "    words = input_text.split()\n",
        "    noise_free_words = [word for word in words if word not in noise_list]\n",
        "    noise_free_text = \" \".join(noise_free_words)\n",
        "    return noise_free_text\n",
        "\n",
        "# _remove_noise(\"oh i c us here\")\n",
        "tinyCorpusStrLowerPunctNoise = _remove_noise(tinyCorpusStrLowerPunct)\n",
        "tinyCorpusStrLowerPunctNoise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'stray cats are running all over the place i see 10 a day cats are killers they kill billions of animals a year the best food in columbus is the north market brand a is the best tasting cat food around your cat will love it buy brand cat food for your cat brand makes healthy and happy cats the arnold classic came to town this weekend it reminds to be healthy i have nothing to say in summary i have told you nothing healthy cat food'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evR5erGR7KLe"
      },
      "source": [
        "### **3.1 Install  stopword lists.**\n",
        "Stopword lists contain low-information words that we feed into a filter in order to extract them from the text that we want to analyze."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6k7IAFgxTdu"
      },
      "source": [
        "# ONLY DO THIS ONCE\n",
        "# import nltk\n",
        "# nltk.download('all', halt_on_error=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUMIXgIcxTeF"
      },
      "source": [
        "Now that we downloaded the lists to our computers let's take a look at the English stopwords. We will be using these shortly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwYPkirdxTeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ff721c-3a76-4ad0-ee42-61922e168b0d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "swords = stopwords.words('english')\n",
        "len(swords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlVs9i5sxTfc"
      },
      "source": [
        "print(swords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGipdtNLYDHa"
      },
      "source": [
        "###**3.2 Remove Stopwords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOV92_flqTxl"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_tokens = word_tokenize(tinyCorpusStrLowerPunctNoise)\n",
        "print(word_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0sCB-IyrZ8m"
      },
      "source": [
        "tinyCorpusStrLowerPunctNoiseStop = [w for w in word_tokens if not w in swords]\n",
        "\n",
        "tinyCorpusStrLowerPunctNoiseStop = []\n",
        "\n",
        "for w in word_tokens:\n",
        "\tif w not in swords:\n",
        "\t\ttinyCorpusStrLowerPunctNoiseStop.append(w)\n",
        "\n",
        "print(tinyCorpusStrLowerPunctNoiseStop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T86SEpgT02oH"
      },
      "source": [
        "##**4. Stem the Document (= Morphological Analysis)**\n",
        "Words have internal structure. So dogs is really dog+PLURAL and chased is chase+PAST. This structure is called morphology and the analysis step is called morphological analysis. For many classification tasks, we don't care whether the person wrote cats or cat. Or running or runs instead of run. We might want to count all those variants of run simply as run. So instead of having separate attributes for run, running, and runs, we reduce it to one.\n",
        "\n",
        "There are a number of stemming algorithms available to us. Here is how to use the Snowball Stemmer and the Porter Stemmer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RZks0wlxTf5"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "stemmer1 = SnowballStemmer('english')\n",
        "stemmer2 = PorterStemmer()\n",
        "\n",
        "print(stemmer1.stem('cats'))\n",
        "print(stemmer2.stem('cats'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myg5RfcExTgR"
      },
      "source": [
        "## NOTE that stemming does not recognize irregular verbs!\n",
        "\n",
        "print(stemmer1.stem('running'))\n",
        "print(stemmer1.stem('runned'))\n",
        "print(stemmer1.stem('ran'))\n",
        "print(stemmer1.stem('runs'))\n",
        "print(\"\")\n",
        "print(stemmer2.stem('running'))\n",
        "print(stemmer2.stem('runned'))\n",
        "print(stemmer2.stem('ran'))\n",
        "print(stemmer2.stem('runs'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaXTR58f2Mwi"
      },
      "source": [
        "Let's try this with our cats now. NOTE that this does not play well with the stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YevPx4BR2T7L"
      },
      "source": [
        "stemmer1.stem(tinyCorpusStrLowerPunctNoise)\n",
        "# stemmer2.stem(tinyCorpusStrLowerPunctNoiseStop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2noTJGGNvp1"
      },
      "source": [
        "A great summary of all preprocessing techniques in a text cleaning script is here: https://gist.github.com/jiahao87/d57a2535c2ed7315390920ea9296d79f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fCFhVKiO6pL"
      },
      "source": [
        "#**5. Word Cloud**\n",
        "Before we do anything else, let's make a word cloud that shows how the words are distributed within our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV-XlFsePIQ3"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "wordcloud = WordCloud(width = 800, height = 800,\n",
        "                background_color ='white',\n",
        "                min_font_size = 10).generate(tinyCorpusStrLowerPunctNoise)\n",
        "\n",
        "# plot the WordCloud image\n",
        "plt.figure(figsize = (8, 8), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmqaGUx2eCl1"
      },
      "source": [
        "#**6. Sentiment Analysis**\n",
        "To see a sentiment analysis in action, follow [these instructions](https://www.digitalocean.com/community/tutorials/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk)."
      ]
    }
  ]
}